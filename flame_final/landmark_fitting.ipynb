{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### https://github.com/TimoBolkart/TF_FLAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vYHp0QYyCTB-"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/MPI-IS/mesh.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wEbcp5MoCQ0r"
      },
      "outputs": [],
      "source": [
        "# !pip install chumpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0WMhXZCqCOB5"
      },
      "outputs": [],
      "source": [
        "# https://github.com/TimoBolkart/TF_FLAME/blob/master/requirements.txt\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf # tf==1.15.2/ tf-gpu==1.15.2\n",
        "from utils.landmarks import load_embedding, tf_get_model_lmks, tf_project_points\n",
        "from tf_smpl.batch_smpl import SMPL\n",
        "from tensorflow.contrib.opt import ScipyOptimizerInterface as scipy_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lnO5-mO-3NeE"
      },
      "outputs": [],
      "source": [
        "def fit_lmk2d(target_img, target_2d_lmks, model_fname, lmk_face_idx, lmk_b_coords, weights):\n",
        "    '''\n",
        "    Fit FLAME to 2D landmarks\n",
        "    :param target_2d_lmks      target 2D landmarks provided as (num_lmks x 3) matrix\n",
        "    :param model_fname         saved FLAME model\n",
        "    :param lmk_face_idx        face indices of the landmark embedding in the FLAME topology\n",
        "    :param lmk_b_coords        barycentric coordinates of the landmark embedding in the FLAME topology\n",
        "                                (i.e. weighting of the three vertices for the trinagle, the landmark is embedded in\n",
        "    :param weights             weights of the individual objective functions\n",
        "    :param visualize           visualize fitting progress\n",
        "    :return: a mesh with the fitting results\n",
        "    '''\n",
        "\n",
        "    tf_trans = tf.Variable(np.zeros((1,3)), name=\"trans\", dtype=tf.float64, trainable=True)\n",
        "    tf_rot = tf.Variable(np.zeros((1,3)), name=\"rot\", dtype=tf.float64, trainable=True)\n",
        "    tf_pose = tf.Variable(np.zeros((1,12)), name=\"pose\", dtype=tf.float64, trainable=True)\n",
        "    tf_shape = tf.Variable(np.zeros((1,300)), name=\"shape\", dtype=tf.float64, trainable=True)\n",
        "    tf_exp = tf.Variable(np.zeros((1,100)), name=\"expression\", dtype=tf.float64, trainable=True)\n",
        "    smpl = SMPL(model_fname)\n",
        "    tf_model = tf.squeeze(smpl(tf_trans,\n",
        "                               tf.concat((tf_shape, tf_exp), axis=-1),\n",
        "                               tf.concat((tf_rot, tf_pose), axis=-1)))\n",
        "\n",
        "    with tf.Session() as session:\n",
        "        # session.run(tf.global_variables_initializer())\n",
        "\n",
        "        # Mirror landmark y-coordinates\n",
        "        target_2d_lmks[:,1] = target_img.shape[0]-target_2d_lmks[:,1]\n",
        "\n",
        "        lmks_3d = tf_get_model_lmks(tf_model, smpl.f, lmk_face_idx, lmk_b_coords)\n",
        "\n",
        "        s2d = np.mean(np.linalg.norm(target_2d_lmks-np.mean(target_2d_lmks, axis=0), axis=1))\n",
        "        s3d = tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(lmks_3d-tf.reduce_mean(lmks_3d, axis=0))[:, :2], axis=1)))\n",
        "        tf_scale = tf.Variable(s2d/s3d, dtype=lmks_3d.dtype)\n",
        "\n",
        "        # trans = 0.5*np.array((target_img.shape[0], target_img.shape[1]))/tf_scale\n",
        "        # trans = 0.5 * s3d * np.array((target_img.shape[0], target_img.shape[1])) / s2d\n",
        "        lmks_proj_2d = tf_project_points(lmks_3d, tf_scale, np.zeros(2))\n",
        "\n",
        "        factor = max(max(target_2d_lmks[:,0]) - min(target_2d_lmks[:,0]),max(target_2d_lmks[:,1]) - min(target_2d_lmks[:,1]))\n",
        "        lmk_dist = weights['lmk']*tf.reduce_sum(tf.square(tf.subtract(lmks_proj_2d, target_2d_lmks))) / (factor ** 2)\n",
        "        neck_pose_reg = weights['neck_pose']*tf.reduce_sum(tf.square(tf_pose[:,:3]))\n",
        "        jaw_pose_reg = weights['jaw_pose']*tf.reduce_sum(tf.square(tf_pose[:,3:6]))\n",
        "        eyeballs_pose_reg = weights['eyeballs_pose']*tf.reduce_sum(tf.square(tf_pose[:,6:]))\n",
        "        shape_reg = weights['shape']*tf.reduce_sum(tf.square(tf_shape))\n",
        "        exp_reg = weights['expr']*tf.reduce_sum(tf.square(tf_exp))\n",
        "\n",
        "        session.run(tf.global_variables_initializer())\n",
        "\n",
        "        def on_step(*_):\n",
        "            # print(tf_exp.numpy())\n",
        "            pass\n",
        "\n",
        "        print('Optimize rigid transformation')\n",
        "        vars = [tf_scale, tf_trans, tf_rot]\n",
        "        loss = lmk_dist\n",
        "        optimizer = scipy_pt(loss=loss, var_list=vars, method='L-BFGS-B', options={'disp': 1, 'ftol': 5e-6})\n",
        "        optimizer.minimize(session, fetches=[tf_model, tf_scale, tf.constant(smpl.f), tf.constant(target_img), tf.constant(target_2d_lmks), lmks_proj_2d], loss_callback=on_step)\n",
        "\n",
        "        print('Optimize model parameters')\n",
        "        vars = [tf_scale, tf_trans[:2], tf_rot, tf_pose, tf_shape, tf_exp]\n",
        "        loss = lmk_dist + shape_reg + exp_reg + neck_pose_reg + jaw_pose_reg + eyeballs_pose_reg\n",
        "        optimizer = scipy_pt(loss=loss, var_list=vars, method='L-BFGS-B', options={'disp': 0, 'ftol': 1e-7})\n",
        "        optimizer.minimize(session, fetches=[tf_model, tf_scale, tf.constant(smpl.f), tf.constant(target_img), tf.constant(target_2d_lmks), lmks_proj_2d,\n",
        "                                             lmk_dist, shape_reg, exp_reg, neck_pose_reg, jaw_pose_reg, eyeballs_pose_reg], loss_callback=on_step)\n",
        "\n",
        "        print('Fitting done')\n",
        "        np_verts, np_scale, np_shape, np_exp, np_trans, np_rot, np_pose = session.run([tf_model, tf_scale, tf_shape, tf_exp, tf_trans, tf_rot, tf_pose])\n",
        "        \n",
        "        # for interactive viewwer\n",
        "        print(\"First 10 shape values:\")\n",
        "        print(np.round(np_shape[0][:10], 2))\n",
        "        print(\"First 10 expression values:\")\n",
        "        print(np.round(np_exp[0][:10], 2))\n",
        "        \n",
        "        return np_verts, np_scale, np_shape, np_exp, np_trans, np_rot, np_pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "imCYk8hf2cvc"
      },
      "outputs": [],
      "source": [
        "def run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path):\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    lmk_face_idx, lmk_b_coords = load_embedding(flame_lmk_path)\n",
        "    target_img = cv2.imread(target_img_path)\n",
        "    lmk_2d = np.load(target_lmk_path)\n",
        "\n",
        "    weights = {}\n",
        "    # Weight of the landmark distance term\n",
        "    weights['lmk'] = 1.0\n",
        "    # Weight of the shape regularizer\n",
        "    weights['shape'] = 1e-3\n",
        "    # Weight of the expression regularizer\n",
        "    weights['expr'] = 1e-3\n",
        "    # Weight of the neck pose (i.e. neck rotationh around the neck) regularizer\n",
        "    weights['neck_pose'] = 100.0\n",
        "    # Weight of the jaw pose (i.e. jaw rotation for opening the mouth) regularizer\n",
        "    weights['jaw_pose'] = 1e-3\n",
        "    # Weight of the eyeball pose (i.e. eyeball rotations) regularizer\n",
        "    weights['eyeballs_pose'] = 10.0\n",
        "\n",
        "    # result_mesh, result_scale = fit_lmk2d(target_img, lmk_2d, model_fname, lmk_face_idx, lmk_b_coords, weights)\n",
        "    np_verts, np_scale, np_shape, np_exp, np_trans, np_rot, np_pose = fit_lmk2d(target_img, lmk_2d, model_fname, lmk_face_idx, lmk_b_coords, weights)\n",
        "    \n",
        "    image_basename = os.path.splitext(os.path.basename(target_img_path))[0]\n",
        "    model_basename = os.path.splitext(os.path.basename(model_fname))[0]\n",
        "    num_lmk = str(len(lmk_face_idx))\n",
        "    basename = image_basename + \"_\" + model_basename + \"_\" + num_lmk\n",
        "    basepath = os.path.join(out_path, basename)\n",
        "    \n",
        "    # save required\n",
        "    np.save(basepath + \"_verts\", np_verts)\n",
        "    np.save(basepath + \"_scale\", np_scale)\n",
        "    np.save(basepath + \"_shape\", np_shape)\n",
        "    np.save(basepath + \"_exp\", np_exp)\n",
        "    np.save(basepath + \"_trans\", np_trans)\n",
        "    np.save(basepath + \"_rot\", np_rot)\n",
        "    np.save(basepath + \"_pose\", np_pose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_path = \"./data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_fname = \"./generic_model.pkl\"\n",
        "target_img_path = \"./data/imgHQ01148.jpeg\"\n",
        "target_lmk_path = \"./data/imgHQ01148_lmks_68.npy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimize rigid transformation\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.027159\n",
            "  Number of iterations: 16\n",
            "  Number of functions evaluations: 21\n",
            "Optimize model parameters\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.010990\n",
            "  Number of iterations: 151\n",
            "  Number of functions evaluations: 168\n",
            "Fitting done\n",
            "First 10 shape values:\n",
            "[ 0.56 -0.1   0.2  -0.49  0.07  0.21 -0.34 -0.01  0.05  0.31]\n",
            "First 10 expression values:\n",
            "[ 0.3  -0.04  0.03  0.15  0.22  0.33 -0.11 -0.13 -0.16  0.37]\n"
          ]
        }
      ],
      "source": [
        "if target_lmk_path[-6:-4] == \"51\":\n",
        "    flame_lmk_path = \"./flame_static_embedding.pkl\"\n",
        "elif target_lmk_path[-6:-4] == \"68\":\n",
        "    flame_lmk_path = \"./flame_static_embedding_68.pkl\"\n",
        "else:\n",
        "    flame_lmk_path = \"./flame_static_embedding.pkl\"\n",
        "run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
