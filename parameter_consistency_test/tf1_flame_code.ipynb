{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vYHp0QYyCTB-"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/MPI-IS/mesh.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wEbcp5MoCQ0r"
      },
      "outputs": [],
      "source": [
        "# !pip install chumpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0WMhXZCqCOB5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# from psbody.mesh import Mesh\n",
        "# from psbody.mesh.meshviewer import MeshViewers\n",
        "from utils.landmarks import load_embedding, tf_get_model_lmks, tf_project_points\n",
        "from tf_smpl.batch_smpl import SMPL\n",
        "from tensorflow.contrib.opt import ScipyOptimizerInterface as scipy_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lnO5-mO-3NeE"
      },
      "outputs": [],
      "source": [
        "def fit_lmk2d(target_img, target_2d_lmks, model_fname, lmk_face_idx, lmk_b_coords, weights):\n",
        "    '''\n",
        "    Fit FLAME to 2D landmarks\n",
        "    :param target_2d_lmks      target 2D landmarks provided as (num_lmks x 3) matrix\n",
        "    :param model_fname         saved FLAME model\n",
        "    :param lmk_face_idx        face indices of the landmark embedding in the FLAME topology\n",
        "    :param lmk_b_coords        barycentric coordinates of the landmark embedding in the FLAME topology\n",
        "                                (i.e. weighting of the three vertices for the trinagle, the landmark is embedded in\n",
        "    :param weights             weights of the individual objective functions\n",
        "    :param visualize           visualize fitting progress\n",
        "    :return: a mesh with the fitting results\n",
        "    '''\n",
        "\n",
        "    tf_trans = tf.Variable(np.zeros((1,3)), name=\"trans\", dtype=tf.float64, trainable=True)\n",
        "    tf_rot = tf.Variable(np.zeros((1,3)), name=\"rot\", dtype=tf.float64, trainable=True)\n",
        "    tf_pose = tf.Variable(np.zeros((1,12)), name=\"pose\", dtype=tf.float64, trainable=True)\n",
        "    tf_shape = tf.Variable(np.zeros((1,300)), name=\"shape\", dtype=tf.float64, trainable=True)\n",
        "    tf_exp = tf.Variable(np.zeros((1,100)), name=\"expression\", dtype=tf.float64, trainable=True)\n",
        "    smpl = SMPL(model_fname)\n",
        "    tf_model = tf.squeeze(smpl(tf_trans,\n",
        "                               tf.concat((tf_shape, tf_exp), axis=-1),\n",
        "                               tf.concat((tf_rot, tf_pose), axis=-1)))\n",
        "\n",
        "    with tf.Session() as session:\n",
        "        # session.run(tf.global_variables_initializer())\n",
        "\n",
        "        # Mirror landmark y-coordinates\n",
        "        target_2d_lmks[:,1] = target_img.shape[0]-target_2d_lmks[:,1]\n",
        "\n",
        "        lmks_3d = tf_get_model_lmks(tf_model, smpl.f, lmk_face_idx, lmk_b_coords)\n",
        "\n",
        "        s2d = np.mean(np.linalg.norm(target_2d_lmks-np.mean(target_2d_lmks, axis=0), axis=1))\n",
        "        s3d = tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(lmks_3d-tf.reduce_mean(lmks_3d, axis=0))[:, :2], axis=1)))\n",
        "        tf_scale = tf.Variable(s2d/s3d, dtype=lmks_3d.dtype)\n",
        "\n",
        "        # trans = 0.5*np.array((target_img.shape[0], target_img.shape[1]))/tf_scale\n",
        "        # trans = 0.5 * s3d * np.array((target_img.shape[0], target_img.shape[1])) / s2d\n",
        "        lmks_proj_2d = tf_project_points(lmks_3d, tf_scale, np.zeros(2))\n",
        "\n",
        "        factor = max(max(target_2d_lmks[:,0]) - min(target_2d_lmks[:,0]),max(target_2d_lmks[:,1]) - min(target_2d_lmks[:,1]))\n",
        "        lmk_dist = weights['lmk']*tf.reduce_sum(tf.square(tf.subtract(lmks_proj_2d, target_2d_lmks))) / (factor ** 2)\n",
        "        neck_pose_reg = weights['neck_pose']*tf.reduce_sum(tf.square(tf_pose[:,:3]))\n",
        "        jaw_pose_reg = weights['jaw_pose']*tf.reduce_sum(tf.square(tf_pose[:,3:6]))\n",
        "        eyeballs_pose_reg = weights['eyeballs_pose']*tf.reduce_sum(tf.square(tf_pose[:,6:]))\n",
        "        shape_reg = weights['shape']*tf.reduce_sum(tf.square(tf_shape))\n",
        "        exp_reg = weights['expr']*tf.reduce_sum(tf.square(tf_exp))\n",
        "\n",
        "        session.run(tf.global_variables_initializer())\n",
        "\n",
        "        def on_step(*_):\n",
        "            # print(tf_exp.numpy())\n",
        "            pass\n",
        "\n",
        "        print('Optimize rigid transformation')\n",
        "        vars = [tf_scale, tf_trans, tf_rot]\n",
        "        loss = lmk_dist\n",
        "        optimizer = scipy_pt(loss=loss, var_list=vars, method='L-BFGS-B', options={'disp': 1, 'ftol': 5e-6})\n",
        "        optimizer.minimize(session, fetches=[tf_model, tf_scale, tf.constant(smpl.f), tf.constant(target_img), tf.constant(target_2d_lmks), lmks_proj_2d], loss_callback=on_step)\n",
        "\n",
        "        print('Optimize model parameters')\n",
        "        vars = [tf_scale, tf_trans[:2], tf_rot, tf_pose, tf_shape, tf_exp]\n",
        "        loss = lmk_dist + shape_reg + exp_reg + neck_pose_reg + jaw_pose_reg + eyeballs_pose_reg\n",
        "        optimizer = scipy_pt(loss=loss, var_list=vars, method='L-BFGS-B', options={'disp': 0, 'ftol': 1e-7})\n",
        "        optimizer.minimize(session, fetches=[tf_model, tf_scale, tf.constant(smpl.f), tf.constant(target_img), tf.constant(target_2d_lmks), lmks_proj_2d,\n",
        "                                             lmk_dist, shape_reg, exp_reg, neck_pose_reg, jaw_pose_reg, eyeballs_pose_reg], loss_callback=on_step)\n",
        "\n",
        "        print('Fitting done')\n",
        "        np_verts, np_scale, np_shape, np_exp, np_trans, np_rot, np_pose = session.run([tf_model, tf_scale, tf_shape, tf_exp, tf_trans, tf_rot, tf_pose])\n",
        "        # print(\"First 10 shape values:\")\n",
        "        # print(np.round(np_shape[0][:10], 2))\n",
        "        # print(\"First 10 expression values:\")\n",
        "        # print(np.round(np_exp[0][:10], 2))\n",
        "        return np_verts, np_scale, np_shape, np_exp, np_trans, np_rot, np_pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "imCYk8hf2cvc"
      },
      "outputs": [],
      "source": [
        "def run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path):\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    lmk_face_idx, lmk_b_coords = load_embedding(flame_lmk_path)\n",
        "    target_img = cv2.imread(target_img_path)\n",
        "    lmk_2d = np.load(target_lmk_path)\n",
        "\n",
        "    weights = {}\n",
        "    # Weight of the landmark distance term\n",
        "    weights['lmk'] = 1.0\n",
        "    # Weight of the shape regularizer\n",
        "    weights['shape'] = 1e-3\n",
        "    # Weight of the expression regularizer\n",
        "    weights['expr'] = 1e-3\n",
        "    # Weight of the neck pose (i.e. neck rotationh around the neck) regularizer\n",
        "    weights['neck_pose'] = 100.0\n",
        "    # Weight of the jaw pose (i.e. jaw rotation for opening the mouth) regularizer\n",
        "    weights['jaw_pose'] = 1e-3\n",
        "    # Weight of the eyeball pose (i.e. eyeball rotations) regularizer\n",
        "    weights['eyeballs_pose'] = 10.0\n",
        "\n",
        "    # result_mesh, result_scale = fit_lmk2d(target_img, lmk_2d, model_fname, lmk_face_idx, lmk_b_coords, weights)\n",
        "    np_verts, np_scale, np_shape, np_exp, np_trans, np_rot, np_pose = fit_lmk2d(target_img, lmk_2d, model_fname, lmk_face_idx, lmk_b_coords, weights)\n",
        "    fname = os.path.join(out_path, os.path.splitext(os.path.basename(target_img_path))[0])\n",
        "    np.save(fname + \"_\" + \"np_verts\", np_verts)\n",
        "    np.save(fname + \"_\" + \"np_scale\", np_scale)\n",
        "    np.save(fname + \"_\" + \"np_shape\", np_shape)\n",
        "    np.save(fname + \"_\" + \"np_exp\", np_exp)\n",
        "    np.save(fname + \"_\" + \"np_trans\", np_trans)\n",
        "    np.save(fname + \"_\" + \"np_rot\", np_rot)\n",
        "    np.save(fname + \"_\" + \"np_pose\", np_pose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_fname = \"./generic_model.pkl\"\n",
        "flame_lmk_path = \"./flame_static_embedding.pkl\"\n",
        "out_path = \"./results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "75\n",
            "Optimize rigid transformation\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.218029\n",
            "  Number of iterations: 23\n",
            "  Number of functions evaluations: 26\n",
            "Optimize model parameters\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.024641\n",
            "  Number of iterations: 310\n",
            "  Number of functions evaluations: 339\n",
            "Fitting done\n"
          ]
        }
      ],
      "source": [
        "for i in range(75, 76):\n",
        "    print()\n",
        "    print()\n",
        "    print()\n",
        "    print(i)\n",
        "    file_name = f\"frame_{str(i).zfill(3)}\"\n",
        "    target_img_path = \"results/\" + file_name + \".jpg\"\n",
        "    target_lmk_path = \"results/\" + file_name + \"_lmks.npy\"\n",
        "    run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qT-tpu1a2F5r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\palla\\anaconda3\\envs\\tf1_flame\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py:2825: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "Optimize rigid transformation\n",
            "WARNING:tensorflow:From c:\\Users\\palla\\anaconda3\\envs\\tf1_flame\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.175327\n",
            "  Number of iterations: 23\n",
            "  Number of functions evaluations: 27\n",
            "Optimize model parameters\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.037823\n",
            "  Number of iterations: 182\n",
            "  Number of functions evaluations: 196\n",
            "Fitting done\n",
            "First 10 shape values:\n",
            "[ 0.71 -0.34 -0.7   0.07 -0.45 -0.05  0.39 -0.18 -0.03 -0.45]\n",
            "First 10 expression values:\n",
            "[ 2.78  0.15 -0.6   0.06 -0.18  0.64  1.28 -0.03 -0.29 -0.07]\n"
          ]
        }
      ],
      "source": [
        "target_img_path = \"./imgHQ00039.jpeg\"\n",
        "target_lmk_path = \"./imgHQ00039_lmks.npy\"\n",
        "run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimize rigid transformation\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.071781\n",
            "  Number of iterations: 22\n",
            "  Number of functions evaluations: 25\n",
            "Optimize model parameters\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.017228\n",
            "  Number of iterations: 232\n",
            "  Number of functions evaluations: 256\n",
            "Fitting done\n",
            "First 10 shape values:\n",
            "[ 0.98  0.25  0.47 -0.21  0.37  0.1  -0.17  0.18 -0.1  -0.02]\n",
            "First 10 expression values:\n",
            "[ 0.22  1.01  0.12  0.69  0.16  0.09  0.32 -0.36 -0.21  0.46]\n"
          ]
        }
      ],
      "source": [
        "target_img_path = \"./imgHQ00088.jpeg\"\n",
        "target_lmk_path = \"./imgHQ00088_lmks.npy\"\n",
        "run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimize rigid transformation\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.089902\n",
            "  Number of iterations: 34\n",
            "  Number of functions evaluations: 42\n",
            "Optimize model parameters\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.027501\n",
            "  Number of iterations: 284\n",
            "  Number of functions evaluations: 310\n",
            "Fitting done\n",
            "First 10 shape values:\n",
            "[-0.1  -0.07 -0.47 -0.25  0.09 -0.45  0.62  0.03 -0.38  0.03]\n",
            "First 10 expression values:\n",
            "[ 2.09 -0.29 -0.44 -0.07 -0.13  0.22  0.34 -0.11  0.04 -0.04]\n"
          ]
        }
      ],
      "source": [
        "target_img_path = \"./imgHQ00095.jpeg\"\n",
        "target_lmk_path = \"./imgHQ00095_lmks.npy\"\n",
        "run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimize rigid transformation\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.021805\n",
            "  Number of iterations: 9\n",
            "  Number of functions evaluations: 13\n",
            "Optimize model parameters\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.012396\n",
            "  Number of iterations: 82\n",
            "  Number of functions evaluations: 87\n",
            "Fitting done\n",
            "First 10 shape values:\n",
            "[ 0.38  0.    0.12  0.05  0.01  0.06 -0.12 -0.11  0.05  0.04]\n",
            "First 10 expression values:\n",
            "[ 0.52  0.14  0.06  0.12  0.04  0.2   0.45 -0.09 -0.2   0.26]\n"
          ]
        }
      ],
      "source": [
        "target_img_path = \"./imgHQ01148.jpeg\"\n",
        "target_lmk_path = \"./imgHQ01148_lmks.npy\"\n",
        "run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimize rigid transformation\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.028856\n",
            "  Number of iterations: 26\n",
            "  Number of functions evaluations: 30\n",
            "Optimize model parameters\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.015275\n",
            "  Number of iterations: 277\n",
            "  Number of functions evaluations: 303\n",
            "Fitting done\n",
            "First 10 shape values:\n",
            "[ 0.75 -0.06 -0.06 -0.2   0.14  0.11 -0.07 -0.18  0.09 -0.04]\n",
            "First 10 expression values:\n",
            "[ 0.13  0.4  -0.04  0.22  0.26  0.2  -0.24 -0.04 -0.13  0.25]\n"
          ]
        }
      ],
      "source": [
        "target_img_path = \"./4.png\"\n",
        "target_lmk_path = \"./4_lmks.npy\"\n",
        "run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimize rigid transformation\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.098053\n",
            "  Number of iterations: 21\n",
            "  Number of functions evaluations: 26\n",
            "Optimize model parameters\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.031389\n",
            "  Number of iterations: 410\n",
            "  Number of functions evaluations: 447\n",
            "Fitting done\n",
            "First 10 shape values:\n",
            "[ 1.5  -0.62 -0.37  0.14 -0.92 -0.17  0.22 -0.58  0.54 -0.2 ]\n",
            "First 10 expression values:\n",
            "[-0.23  0.32  0.33 -0.36 -0.19  0.17 -0.25  0.23  0.25 -0.41]\n"
          ]
        }
      ],
      "source": [
        "target_img_path = \"./sad_small.jpg\"\n",
        "target_lmk_path = \"./sad_small_lmks.npy\"\n",
        "run_2d_lmk_fitting(model_fname, flame_lmk_path, target_img_path, target_lmk_path, out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
